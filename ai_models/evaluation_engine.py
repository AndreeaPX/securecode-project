from __future__ import annotations

import json
import tempfile
from pathlib import Path
from typing import Dict, Any, List
import shap
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from django.conf import settings
from django.db import transaction
from django.utils import timezone

from ai_models.features import extract_features_for_assignment
from ai_models.predictor import MODEL_PATH, load_model
from ai_models.trainer import train_and_save_model
from ai_models.verdict_engine import get_verdict_for_assignment
from users.models.tests import TestAssignment
from contextlib import contextmanager

try:
    from .tasks import build_pdf_report_async, retrain_model_async  # type: ignore
    HAVE_CELERY = True
except ImportError:
    HAVE_CELERY = False

@contextmanager
def bold(canvas):
    old_font = canvas._fontname
    old_size = canvas._fontsize
    canvas.setFont("Helvetica-Bold", old_size)
    yield
    canvas.setFont(old_font, old_size)

def _gather_evidence_images(assignment: TestAssignment) -> List[Path]:
    frame_dir = Path(settings.BASE_DIR) / "frame_logs"
    if not frame_dir.exists():
        return []
    prefix = f"{assignment.id}_"
    return sorted([p for p in frame_dir.glob("*.jpg") if prefix in p.name], key=lambda p: p.stat().st_mtime, reverse=True)[:4]

def _contextual_filter(features: Dict[str, Any], assignment: TestAssignment) -> Dict[str, Any]:
    f = dict(features)
    t = assignment.test
    if not t.allow_sound_analysis:
        for col in ("voiced_seconds", "mouth_open_no_voice_count", "too_much_talking_count", "voice_detected_count"):
            f[col] = 0
    if not t.use_proctoring and not t.has_ai_assistent:
        for col in ("esc_pressed_count", "second_screen_events", "tab_switches_count", "window_blur_count", "copy_paste_events", "gaze_left_count", "gaze_right_count", "gaze_down_count", "multiple_faces_detected", "face_mismatch_count", "mobile_detected_count"):
            f[col] = 0
    return f

def _json_safe(o):
    if isinstance(o, (np.integer, np.int32, np.int64)):
        return int(o)
    if isinstance(o, (np.floating, np.float32, np.float64)):
        return float(o)
    if isinstance(o, dict):
        return {k: _json_safe(v) for k, v in o.items()}
    if isinstance(o, list):
        return [_json_safe(v) for v in o]
    return o

def evaluate_assignment(assignment: TestAssignment) -> Dict[str, Any]:
    raw = extract_features_for_assignment(assignment)
    ctx = _contextual_filter(raw, assignment)
    verdict = get_verdict_for_assignment(assignment, features=ctx)
    assignment.ai_cheating = verdict["cheating"]
    assignment.ai_probability = verdict.get("probability")
    assignment.rule_triggered = verdict.get("rule_triggered", False)
    assignment.ai_details_json = json.dumps(_json_safe(verdict))
    assignment.ai_evaluated_at = timezone.now()
    assignment.save(update_fields=["ai_cheating", "ai_probability", "rule_triggered", "ai_details_json", "ai_evaluated_at"])
    if HAVE_CELERY:
        build_pdf_report_async.delay(assignment.id)
    else:
        build_pdf_report(assignment)
    return verdict

def apply_professor_verdict(assignment: TestAssignment, professor_verdict: bool, professor_user, override_comment: str | None = None) -> None:
    with transaction.atomic():
        original_ai = assignment.ai_cheating
        assignment.final_verdict = professor_verdict
        assignment.reviewed_by = professor_user
        assignment.reviewed_at = timezone.now()
        assignment.review_comment = override_comment or ""
        assignment.save(update_fields=["final_verdict", "reviewed_by", "reviewed_at", "review_comment"])
        if original_ai != professor_verdict and not assignment.rule_triggered:
            assignment.label = not professor_verdict
            assignment.save(update_fields=["label"])
            if HAVE_CELERY:
                retrain_model_async.delay()
            else:
                train_and_save_model()

_FEATURE_DESC = {
    "mobile_detected_flag": "Phone detected by camera",
    "tab_switches_count": "Switched tabs multiple times",
    "multiple_faces_detected": "Multiple faces visible",
    "copy_paste_events": "Frequent copy-paste activity",
    "key_press_count": "Very low typing effort",
    "typing_speed_suspect": "Typing speed abnormal",
    "total_gaze_offscreen": "Looking away from screen repeatedly",
    "window_blur_count": "Lost focus on exam tab",
    "too_much_talking_count": "Excessive talking detected",
}

def build_pdf_report(assignment: TestAssignment) -> Path:
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.units import mm
    from reportlab.pdfgen import canvas as rl_canvas

    model = load_model(MODEL_PATH)
    verdict = json.loads(assignment.ai_details_json or "{}")
    evidence = _gather_evidence_images(assignment)
    features = _contextual_filter(extract_features_for_assignment(assignment), assignment)

    # Ensure derived features reflect rule triggers (especially for SHAP)
    from ai_models.trainer import add_derived_features  # reuse your existing helper
    features = add_derived_features(features)
    

    if verdict.get("rule_triggered"):
        reason = verdict.get("rule_reason", "").lower()
        if "phone" in reason:
            features["mobile_detected_flag"] = 1
        if "multiple faces" in reason:
            features["multiple_faces_detected"] = 2
        if "face mismatch" in reason:
            features["face_mismatch_count"] = 2
        if "pasted too fast" in reason:
            features["chars_per_minute"] = 800
            features["key_press_count"] = 1
        if "no key-presses" in reason:
            features["key_press_count"] = 0
            features["total_chars"] = 500
        if "copy-paste" in reason:
            features["copy_paste_events"] = 5
            features["avg_key_delay"] = 10
        if "talking without visible mouth" in reason:
            features["voiced_seconds"] = 35
            features["mouth_open_no_voice_count"] = 3
        if "reading something off-screen" in reason:
            features["gaze_down_count"] = 3
            features["head_down_count"] = 3
            features["voice_detected_count"] = 3
        if "switched tabs" in reason:
            features["tab_switches_count"] = 2

    expected_features = model.get_booster().feature_names
    cleaned_features = {k: features.get(k, 0) for k in expected_features}
    X = pd.DataFrame([cleaned_features], columns=expected_features)
    shap_explainer = shap.TreeExplainer(model)
    shap_vals = shap_explainer.shap_values(X)
    if isinstance(shap_vals, list):
        shap_vals = shap_vals[1]

    rule_triggered_features = set()
    if verdict.get("rule_triggered"):
        reason = verdict.get("rule_reason", "").lower()
        boost_map = {
            "phone": "mobile_detected_flag",
            "multiple faces": "multiple_faces_detected",
            "face mismatch": "face_mismatch_count",
            "pasted too fast": "chars_per_minute",
            "no key-presses": "total_chars",
            "copy-paste": "copy_paste_events",
            "talking without": "voiced_seconds",
            "reading something": "gaze_down_count",
            "switched tabs" : "tab_switches_count",
        }
        for key, feature in boost_map.items():
            if key in reason and feature in X.columns:
                idx = list(X.columns).index(feature)
                shap_vals[0][idx] = max(shap_vals[0]) + 2.5  
                rule_triggered_features.add(feature)

    shap_series = pd.Series(shap_vals[0], index=X.columns)
    sorted_shap = shap_series.abs().sort_values(ascending=False)
    top_features = sorted_shap.head(10).index

    fig, ax = plt.subplots(figsize=(12, 5))
    bar_colors = ["crimson" if f in rule_triggered_features else "dodgerblue" for f in reversed(top_features)]

    bars = ax.barh(
        y=list(reversed(top_features)),
        width=[shap_series[f] for f in reversed(top_features)],
        color=bar_colors
    )


    for bar, feat in zip(bars, reversed(top_features)):
        val = X.iloc[0][feat]
        label = f"{val:.1f}" if isinstance(val, float) else str(int(val))
        ax.text(
            x=bar.get_width() + 0.05 if bar.get_width() >= 0 else bar.get_width() - 0.05,
            y=bar.get_y() + bar.get_height() / 2,
            s=label,
            va="center",
            ha="left" if bar.get_width() >= 0 else "right",
            fontsize=9
        )

    ax.set_xlabel("SHAP value (impact on model output)")
    ax.set_title("Top SHAP Features (with actual values)")
    plt.tight_layout()

    tmp_img_path = Path(tempfile.gettempdir()) / f"shap_plot_{assignment.id}.png"
    plt.savefig(tmp_img_path, dpi=150)
    plt.close()

    out_dir = Path(settings.MEDIA_ROOT) / "reports"
    out_dir.mkdir(parents=True, exist_ok=True)
    pdf_path = out_dir / f"assignment_{assignment.id}.pdf"
    c = rl_canvas.Canvas(str(pdf_path), pagesize=A4)
    width, height = A4

    # Metadata
    student_name = f"{assignment.student.first_name} {assignment.student.last_name}".strip() or assignment.student.email
    verdict_txt = "CHEATING" if verdict.get("cheating") else "NOT CHEATING"
    confidence = f"{verdict.get('probability', 0) * 100:.1f}%"

    y = height - 20 * mm
    c.setFont("Helvetica-Bold", 16)
    c.drawString(20 * mm, y, f"Exam Report â€“ Assignment #{assignment.id}")

    c.setFont("Helvetica", 10)
    y -= 10 * mm
    c.drawString(20 * mm, y, f"Student: {student_name}")
    y -= 6 * mm
    c.drawString(20 * mm, y, f"Email: {assignment.student.email}")
    y -= 6 * mm
    c.drawString(20 * mm, y, f"Test: {assignment.test.name}")
    y -= 6 * mm
    c.drawString(20 * mm, y, f"Attempt: {assignment.attempt_no}")

    y -= 10 * mm
    c.setFont("Helvetica-Bold", 12)
    c.drawString(20 * mm, y, "AI Verdict:")
    c.setFont("Helvetica", 10)
    y -= 6 * mm
    c.drawString(25 * mm, y, f"- Verdict: {verdict_txt}")
    y -= 6 * mm
    c.drawString(25 * mm, y, f"- Confidence: {confidence}")
    y -= 6 * mm
    reason = verdict.get("reason")
    c.drawString(25*mm, y, f"- Reason: {reason if reason else 'AI-based classification'}")


    if verdict.get("rule_triggered"):
        y -= 8 * mm
        c.setFont("Helvetica-Bold", 11)
        c.drawString(20 * mm, y, "Rule-Based Trigger:")
        y -= 6 * mm
        c.setFont("Helvetica", 10)
        c.drawString(25 * mm, y, f"- {verdict.get('rule_reason', 'Unspecified reason')}")

    # Embed SHAP summary diagram
    y -= 12 * mm
    img_w, img_h = 180 * mm, 110 * mm          # make it wide & clear
    c.drawImage(str(tmp_img_path), 20 * mm, y - img_h, width=img_w, height=img_h, preserveAspectRatio=True)
    y -= img_h


    # Evidence images
    y -= 15 * mm
    img_w, img_h = 75 * mm, 55 * mm
    for idx, img_path in enumerate(evidence):
        x = 20 * mm + (idx % 2) * (img_w + 10 * mm)
        if idx and idx % 2 == 0:
            y -= img_h + 10 * mm
        c.drawImage(str(img_path), x, y, width=img_w, height=img_h, preserveAspectRatio=True)

    c.showPage()
    c.save()
    return pdf_path


if not HAVE_CELERY:
    def build_pdf_report_async(assignment_id: int):  # type: ignore
        build_pdf_report(TestAssignment.objects.get(id=assignment_id))
    def retrain_model_async():  # type: ignore
        train_and_save_model()